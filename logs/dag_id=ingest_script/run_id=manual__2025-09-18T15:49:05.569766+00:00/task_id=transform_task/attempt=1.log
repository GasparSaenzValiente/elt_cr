{"timestamp":"2025-09-18T15:49:22.762744","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-18T15:49:22.763055","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/cr_ingestion_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-18T15:49:23.857318Z","level":"error","event":"25/09/18 15:49:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:23.981478Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:23.981706Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:25.797030Z","level":"error","event":"25/09/18 15:49:25 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.339580Z","level":"error","event":"25/09/18 15:49:26 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: s3a://raw-data/players.json.","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.339769Z","level":"error","event":"org.apache.hadoop.fs.s3a.UnknownStoreException: `s3a://raw-data/players.json': getFileStatus on s3a://raw-data/players.json: com.amazonaws.services.s3.model.AmazonS3Exception: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D5BD1ED4; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8:NoSuchBucket: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D5BD1ED4; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.339859Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:263)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.339925Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:175)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.339990Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3858)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340047Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340101Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$isDirectory$35(S3AFileSystem.java:4724)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340169Z","level":"error","event":"\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340231Z","level":"error","event":"\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340304Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340362Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340425Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.isDirectory(S3AFileSystem.java:4722)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340493Z","level":"error","event":"\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340561Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340621Z","level":"error","event":"\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340677Z","level":"error","event":"\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340744Z","level":"error","event":"\tat scala.Option.getOrElse(Option.scala:189)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340802Z","level":"error","event":"\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340861Z","level":"error","event":"\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340917Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.340973Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341037Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341098Z","level":"error","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341154Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341208Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341261Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341314Z","level":"error","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341367Z","level":"error","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341423Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341483Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341545Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341605Z","level":"error","event":"Caused by: com.amazonaws.services.s3.model.AmazonS3Exception: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D5BD1ED4; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341668Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1879)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341740Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1418)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341803Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1387)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341859Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.341981Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342053Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342110Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342161Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342214Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342280Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342333Z","level":"error","event":"\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342383Z","level":"error","event":"\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5467)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342432Z","level":"error","event":"\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5414)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342485Z","level":"error","event":"\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5408)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342544Z","level":"error","event":"\tat com.amazonaws.services.s3.AmazonS3Client.listObjectsV2(AmazonS3Client.java:971)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342600Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$listObjects$11(S3AFileSystem.java:2595)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342653Z","level":"error","event":"\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342714Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342764Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342819Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.listObjects(S3AFileSystem.java:2586)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342875Z","level":"error","event":"\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3832)","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.342933Z","level":"error","event":"\t... 26 more","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-18T15:49:26.394927","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o33.json.\n: org.apache.hadoop.fs.s3a.UnknownStoreException: `s3a://raw-data/players.json': getFileStatus on s3a://raw-data/players.json: com.amazonaws.services.s3.model.AmazonS3Exception: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D8991D8B; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8:NoSuchBucket: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D8991D8B; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null)\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:263)\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:175)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3858)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$exists$34(S3AFileSystem.java:4703)\n\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4701)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:756)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\nCaused by: com.amazonaws.services.s3.model.AmazonS3Exception: The specified bucket does not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Request ID: 18666B31D8991D8B; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1879)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1418)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1387)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5467)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5414)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5408)\n\tat com.amazonaws.services.s3.AmazonS3Client.listObjectsV2(AmazonS3Client.java:971)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$listObjects$11(S3AFileSystem.java:2595)\n\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.listObjects(S3AFileSystem.java:2586)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3832)\n\t... 23 more\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":216,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":239,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/etl/scripts/transform_data.py","lineno":22,"name":"transform"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/readwriter.py","lineno":425,"name":"json"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
